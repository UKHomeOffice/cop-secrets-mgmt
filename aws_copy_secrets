#!/usr/bin/env python3

from libs import command_parser, command_checker, custom_logger, file_handler, aws_handler, git_handler, data_parser
from pprint import pprint
import os
import re

__version__ = '0.1'

def main():
    current_env = config_data['env']
    new_env = config_data['new_env']
    env_data = data_parser.Tree()
    if 'env_data' not in config_data:
        config_data['env_data'] = dict()
    if 'secrets' not in config_data:
        config_data['secrets'] = dict()
    project_name = config_data['project']

    for repo_name, repo_data in config_data['projects'][project_name]['repos'].items():
        repo_env_data = data_parser.Tree()
        sorter = data_parser.Sorter(data=config_data, io_handle=io_handle)
        base_repo_path = f'/tmp/{name}/repos/'
        if not io_handle.dir_exists(base_repo_path):
            io_handle.make_dir(base_repo_path)
        repo_path = repo_data['path'] = os.path.join(base_repo_path, repo_name)
        repo_data['name'] = repo_name
        data_parser.git_process(repo_data=repo_data)
        env_file = os.path.join(repo_path, repo_data['env_file'])
        logging.debug(f'{repo_name} downloaded to {repo_path}, processing {env_file}')
        repo_env_yaml_data = io_handle.read_file(config_file=env_file, file_type='yaml')

        # flattening the data structure to match existing secrets storage structure / method
        for repo_data in repo_env_yaml_data['keys']:
            repo_env_data.update(sorter.flatten_sort(repo_data, ''))
        old_secrets_list = sorter.create_old_secrets()

        # storing all of the repo specific data in a new env_data dict
        # first storing by repo - this gives us the individual repo secrets
        if repo_name not in env_data:
            env_data[repo_name] = data_parser.Tree()
        env_data[repo_name]['old_secrets_list'] = old_secrets_list
        env_data[repo_name]['old_secrets'].update(repo_env_data)

        # now storing by project name which is a combined list of all secrets from the various repositories
        # associated with this project
        if project_name not in env_data:
            env_data[project_name] = data_parser.Tree()
        if 'old_secrets_list' not in env_data[project_name]:
            env_data[project_name]['old_secrets_list'] = []

        for key, values in repo_env_data.items():
            if key not in env_data[project_name]['old_secrets']:
                env_data[project_name]['old_secrets'][key] = values
            else:
                for val in values:
                    if val not in env_data[project_name]['old_secrets'][key]:
                        env_data[project_name]['old_secrets'][key].append(val)
        for old_secret in old_secrets_list:
            if old_secret not in env_data[project_name]['old_secrets_list']:
                env_data[project_name]['old_secrets_list'].append(old_secret)

    for custom_secret in config_data['projects'][project_name]['custom_secrets']:
        env_data[project_name]['old_secrets']['cerberus'] = custom_secret
        if custom_secret not in env_data[project_name]['old_secrets_list']:
            env_data[project_name]['old_secrets_list'].append(custom_secret)

    aws = aws_handler.AWS(data=config_data)
    aws.get_credentials()

    for old_secret in env_data[project_name].old_secrets_list:
        secret_data = aws.get_secret(secret=old_secret)
        env_data[project_name]['original_secrets'].update(secret_data)

    for secret_key, secret_value in env_data[project_name]['original_secrets'].items():
        new_env_key = re.sub(current_env, new_env, secret_key)

        if isinstance(secret_value, dict):
            for secret_val_key, secret_val_val in secret_value.items():
                new_env_val_key = re.sub(current_env, new_env, secret_val_key)
                new_env_val_val = secret_val_val
                if isinstance(secret_val_val, str):
                    new_env_val_val = re.sub(current_env, new_env, secret_val_val)
                env_data[project_name]['new_env_secrets'][new_env_key][new_env_val_key] = new_env_val_val
        else:
            new_env_val = secret_value
            if isinstance(secret_value, str):
                new_env_val = re.sub(current_env, new_env, secret_value)
            env_data[project_name]['new_env_secrets'][new_env_key] = new_env_val

    for secret_key, secret_value in env_data[project_name]['new_env_secrets'].items():
        response = aws.create_secret(name=secret_key, secret_data=secret_value)
        pprint(response)


if __name__ == "__main__":
    name = 'aws_copy_secrets'
    # initialise the command line checker, add in all of the options
    cmd_opts = command_parser.Commands(name=name, version=__version__)
    cmd_opts.add_config()
    cmd_opts.add_user_auth()
    cmd_opts.add_project()
    cmd_opts.add_env()
    cmd_opts.add_new_env()
    options, args_parser = cmd_opts.set_options()
    # set up the io handling
    io_handle = file_handler.FileHandler()
    # initialise the config data
    if not io_handle.file_exists(options.config):
        raise ValueError(f'Unable to read {options.config}')
    config_data = io_handle.read_file(options.config)
    # set up the logging
    logging = custom_logger.colourLog(name=name)
    # parse through the provided options make sure everything is set as required
    # do init sanity checks and config population
    cmd_check = command_checker.CommandCheck(options=options,
                                             parser=args_parser,
                                             config_data=config_data,
                                             io_handler=io_handle)
    cmd_check.login()
    cmd_check.get_project()
    cmd_check.get_env()

    main()
